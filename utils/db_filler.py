import psycopg2
from psycopg2.extras import execute_values
from faker import Faker
import random
from decouple import config
from datetime import timedelta


# –ó–∞–ø–æ–≤–Ω–µ–Ω–Ω—è —Ç–∞–±–ª–∏—Ü—ñ Companies
def populate_companies(db_config, count=20000):
    fake = Faker()
    
    # –°–ø–∏—Å–æ–∫ —ñ–Ω–¥—É—Å—Ç—Ä—ñ–π –¥–ª—è –ø–æ–≤—Ç–æ—Ä–µ–Ω–Ω—è
    industries = ['IT', 'Finance', 'Healthcare', 'Education', 'Manufacturing', 'Retail', 'Energy']
    
    try:
        conn = psycopg2.connect(**db_config)
        cursor = conn.cursor()
        
        print(f"–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è {count} –∫–æ–º–ø–∞–Ω—ñ–π...")
        
        # –ì–æ—Ç—É—î–º–æ –¥–∞–Ω—ñ —É –ø–∞–º'—è—Ç—ñ
        data = []
        for _ in range(count):
            data.append((
                fake.company(),      # name
                random.choice(industries), # industry
                fake.country()       # country
            ))
        
        # SQL –∑–∞–ø–∏—Ç (–±–µ–∑ id —Ç–∞ created_at, –±–æ –≤–æ–Ω–∏ –≥–µ–Ω–µ—Ä—É—é—Ç—å—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ)
        query = "INSERT INTO companies (name, industry, country) VALUES %s"
        
        print("–ó–∞–ø–∏—Å —É –±–∞–∑—É –¥–∞–Ω–∏—Ö...")
        # execute_values –Ω–∞–±–∞–≥–∞—Ç–æ —à–≤–∏–¥—à–µ –∑–∞ –∑–≤–∏—á–∞–π–Ω–∏–π execute —É —Ü–∏–∫–ª—ñ
        execute_values(cursor, query, data)
        
        conn.commit()
        print(f"–£—Å–ø—ñ—à–Ω–æ –¥–æ–¥–∞–Ω–æ {count} –∫–æ–º–ø–∞–Ω—ñ–π!")
        
    except Exception as e:
        print(f"–ü–æ–º–∏–ª–∫–∞: {e}")
        if conn: 
            conn.rollback()
    finally:
        if cursor: 
            cursor.close()
        if conn: 
            conn.close()


# –ó–∞–ø–æ–≤–Ω–µ–Ω–Ω—è —Ç–∞–±–ª–∏—Ü—ñ Jobs
def populate_jobs(db_config, total_records=1_000_000, chunk_size=10_000):
    fake = Faker()
    categories = ['Engineering', 'Marketing', 'Sales', 'Design', 'HR', 'Support']
    
    try:
        conn = psycopg2.connect(**db_config)
        cursor = conn.cursor()

        # 1. –û—Ç—Ä–∏–º—É—î–º–æ —ñ—Å–Ω—É—é—á—ñ company_id
        print("–û—Ç—Ä–∏–º–∞–Ω–Ω—è ID –∫–æ–º–ø–∞–Ω—ñ–π...")
        cursor.execute("SELECT company_id FROM companies")
        company_ids = [row[0] for row in cursor.fetchall()]
        
        if not company_ids:
            print("–ü–æ–º–∏–ª–∫–∞: –¢–∞–±–ª–∏—Ü—è companies –ø–æ—Ä–æ–∂–Ω—è!")
            return

        print(f"–ü–æ—á–∏–Ω–∞—î–º–æ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—é {total_records} –≤–∞–∫–∞–Ω—Å—ñ–π...")

        inserted = 0
        while inserted < total_records:
            data = []
            for _ in range(min(chunk_size, total_records - inserted)):
                # –õ–æ–≥—ñ–∫–∞ –¥–ª—è –¥–∞—Ç
                posted_at = fake.date_time_between(start_date='-1y', end_date='now')
                last_updated = fake.date_time_between(start_date=posted_at, end_date='now')
                
                # –õ–æ–≥—ñ–∫–∞ –¥–ª—è salary (–±–∞–≥–∞—Ç–æ NULL)
                has_salary = random.random() > 0.4  # 40% –≤–∞–∫–∞–Ω—Å—ñ–π –±—É–¥—É—Ç—å –±–µ–∑ –∑–∞—Ä–ø–ª–∞—Ç–∏ (NULL)
                salary_from = random.randint(500, 5000) if has_salary else None
                salary_to = (salary_from + random.randint(200, 3000)) if salary_from else None

                data.append((
                    random.choice(company_ids),     # company_id
                    fake.job(),                     # title
                    random.choice(categories),      # category
                    fake.city(),                    # location
                    salary_from,                    # salary_from
                    salary_to,                      # salary_to
                    posted_at,                      # posted_at
                    random.choice([True, False]),   # is_active
                    last_updated                    # last_updated
                ))

            # 2. –ú–∞—Å–æ–≤–µ –≤—Å—Ç–∞–≤–ª–µ–Ω–Ω—è –ø–∞—á–∫–∏
            query = """
                INSERT INTO jobs (
                    company_id, title, category, location, 
                    salary_from, salary_to, posted_at, is_active, last_updated
                ) VALUES %s
            """
            execute_values(cursor, query, data)
            conn.commit() # –§—ñ–∫—Å—É—î–º–æ –∫–æ–∂–Ω—É –ø–∞—á–∫—É
            
            inserted += len(data)
            print(f"–ü—Ä–æ–≥—Ä–µ—Å: {inserted}/{total_records} –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ...")

        print("–ì–æ—Ç–æ–≤–æ! –ú—ñ–ª—å–π–æ–Ω –≤–∞–∫–∞–Ω—Å—ñ–π –¥–æ–¥–∞–Ω–æ.")

    except Exception as e:
        print(f"–°—Ç–∞–ª–∞—Å—è –ø–æ–º–∏–ª–∫–∞: {e}")
        if conn: 
            conn.rollback()
    finally:
        if cursor: 
            cursor.close()
        if conn: 
            conn.close()


# –ó–∞–ø–æ–≤–Ω–µ–Ω–Ω—è —Ç–∞–±–ª–∏—Ü—ñ Job_Views
def populate_views(db_config, total_records=50_000_000, chunk_size=50_000):
    """–ó–∞–ø–æ–≤–Ω—é—î —Ç–∞–±–ª–∏—Ü—é job_views –∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—ñ –≤–∞–∫–∞–Ω—Å—ñ–π."""
    try:
        conn = psycopg2.connect(**db_config)
        cursor = conn.cursor()

        # 1. –û—Ç—Ä–∏–º—É—î–º–æ ID –≤–∞–∫–∞–Ω—Å—ñ–π
        print("–û—Ç—Ä–∏–º–∞–Ω–Ω—è ID –≤–∞–∫–∞–Ω—Å—ñ–π...")
        cursor.execute("SELECT job_id, posted_at FROM jobs")
        jobs_data = cursor.fetchall() # –û–±–µ—Ä–µ–∂–Ω–æ, —Ç—É—Ç 1 –º–ª–Ω —Ä—è–¥–∫—ñ–≤
        job_ids = [row[0] for row in jobs_data]
        job_dates = {row[0]: row[1] for row in jobs_data}
        
        # –°—Ç–≤–æ—Ä—é—î–º–æ "–ø–æ–ø—É–ª—è—Ä–Ω—ñ" –≤–∞–∫–∞–Ω—Å—ñ—ó (–ø–µ—Ä—à—ñ 10% —Å–ø–∏—Å–∫—É –±—É–¥—É—Ç—å –æ—Ç—Ä–∏–º—É–≤–∞—Ç–∏ –±—ñ–ª—å—à–µ –ø–µ—Ä–µ–≥–ª—è–¥—ñ–≤)
        popular_jobs = job_ids[:int(len(job_ids) * 0.1)]
        other_jobs = job_ids[int(len(job_ids) * 0.1):]

        print(f"–ü–æ—á–∏–Ω–∞—î–º–æ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—é {total_records} –ø–µ—Ä–µ–≥–ª—è–¥—ñ–≤...")

        inserted = 0
        while inserted < total_records:
            data = []
            for _ in range(min(chunk_size, total_records - inserted)):
                # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–µ—Ä–µ–∫—ñ—Å: —É 80% –≤–∏–ø–∞–¥–∫—ñ–≤ –æ–±–∏—Ä–∞—î–º–æ –∑ –ø–æ–ø—É–ª—è—Ä–Ω–∏—Ö
                if random.random() < 0.8:
                    j_id = random.choice(popular_jobs)
                else:
                    j_id = random.choice(other_jobs)
                
                # –î–∞—Ç–∞ –ø–µ—Ä–µ–≥–ª—è–¥—É –º–∞—î –±—É—Ç–∏ –ü–Ü–°–õ–Ø –¥–∞—Ç–∏ –ø—É–±–ª—ñ–∫–∞—Ü—ñ—ó
                start_date = job_dates[j_id]
                viewed_at = start_date + timedelta(seconds=random.randint(0, 1000000))
                
                data.append((
                    j_id,
                    random.randint(1, 500000), # user_id
                    viewed_at
                ))

            # –í—Å—Ç–∞–≤–∫–∞
            query = "INSERT INTO job_views (job_id, user_id, viewed_at) VALUES %s"
            execute_values(cursor, query, data)
            conn.commit()
            
            inserted += len(data)
            if inserted % 500000 == 0:
                print(f"–ü—Ä–æ–≥—Ä–µ—Å: {inserted}/{total_records} ({(inserted/total_records)*100:.1f}%)")

        print("–ì–æ—Ç–æ–≤–æ!")

    except Exception as e:
        print(f"–ü–æ–º–∏–ª–∫–∞: {e}")
        if conn: 
            conn.rollback()
    finally:
        if cursor: 
            cursor.close()
        if conn: 
            conn.close()


# –ó–∞–ø–æ–≤–Ω–µ–Ω–Ω—è —Ç–∞–±–ª–∏—Ü—ñ Job_Applications
def populate_precise_applications(db_config, target_count=5000000, batch_size=20000):
    statuses = ['applied', 'rejected', 'hired']
    weights = [0.3, 0.65, 0.05] # –ö–æ–Ω–≤–µ—Ä—Å—ñ—è —É –Ω–∞–π–º 5%
    
    conn = None
    read_cursor = None
    write_cursor = None

    try:
        conn = psycopg2.connect(**db_config)
        
        # 1. –°—Ç–≤–æ—Ä—é—î–º–æ —Å–µ—Ä–≤–µ—Ä–Ω–∏–π –∫—É—Ä—Å–æ—Ä –¥–ª—è –ß–ò–¢–ê–ù–ù–Ø.
        # name='...' —Ä–æ–±–∏—Ç—å –π–æ–≥–æ —Å–µ—Ä–≤–µ—Ä–Ω–∏–º (–¥–∞–Ω—ñ –Ω–µ –≤–∞–Ω—Ç–∞–∂–∞—Ç—å—Å—è –≤ RAM –≤—Å—ñ –æ–¥—Ä–∞–∑—É).
        # withhold=True –¥–æ–∑–≤–æ–ª—è—î —Ä–æ–±–∏—Ç–∏ commit() –¥–ª—è –≤—Å—Ç–∞–≤–æ–∫, –Ω–µ –≤–±–∏–≤–∞—é—á–∏ —Ü–µ–π –∫—É—Ä—Å–æ—Ä.
        read_cursor = conn.cursor(name='views_reader_cursor', withhold=True)
        
        # 2. –°—Ç–≤–æ—Ä—é—î–º–æ –∑–≤–∏—á–∞–π–Ω–∏–π –∫—É—Ä—Å–æ—Ä –¥–ª—è –ó–ê–ü–ò–°–£.
        write_cursor = conn.cursor()

        print("–ê–Ω–∞–ª—ñ–∑ —Ç–∞–±–ª–∏—Ü—ñ job_views —Ç–∞ –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –≤–∏–±—ñ—Ä–∫–∏...")
        print("–í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –º–µ—Ç–æ–¥ BERNOULLI –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ—ó —è–∫–æ—Å—Ç—ñ —Ä–æ–∑–ø–æ–¥—ñ–ª—É –¥–∞–Ω–∏—Ö.")
        
        # BERNOULLI(10) —Å–∫–∞–Ω—É—î –≤—Å—é —Ç–∞–±–ª–∏—Ü—é —ñ –±–µ—Ä–µ ~10% —Ä—è–¥–∫—ñ–≤. 
        # –¶–µ –ø–æ–≤—ñ–ª—å–Ω—ñ—à–µ –∑–∞ SYSTEM, –∞–ª–µ –¥–∞—î —ñ–¥–µ–∞–ª—å–Ω–æ —Ä–µ–ø—Ä–µ–∑–µ–Ω—Ç–∞—Ç–∏–≤–Ω—É –≤–∏–±—ñ—Ä–∫—É.
        read_cursor.execute("""
            SELECT job_id, user_id, viewed_at 
            FROM job_views 
            TABLESAMPLE BERNOULLI(10)
        """)
        
        inserted_total = 0
        
        while True:
            # –ß–∏—Ç–∞—î–º–æ –ø–∞—á–∫—É –ø–µ—Ä–µ–≥–ª—è–¥—ñ–≤
            rows = read_cursor.fetchmany(batch_size)
            
            if not rows:
                break # –î–∞–Ω—ñ –∑–∞–∫—ñ–Ω—á–∏–ª–∏—Å—å
            
            # –§–æ—Ä–º—É—î–º–æ –∑–∞—è–≤–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –ø–µ—Ä–µ–≥–ª—è–¥—ñ–≤
            applications_data = []
            for job_id, user_id, viewed_at in rows:
                
                # –õ–æ–≥—ñ–∫–∞: –∑–∞—è–≤–∫–∞ –∑–∞–≤–∂–¥–∏ –ø—ñ–∑–Ω—ñ—à–µ –ø–µ—Ä–µ–≥–ª—è–¥—É (–≤—ñ–¥ 5 —Ö–≤ –¥–æ 5 –¥–Ω—ñ–≤)
                time_delay = timedelta(minutes=random.randint(5, 7200)) 
                applied_at = viewed_at + time_delay
                
                # –í–∏–∑–Ω–∞—á–∞—î–º–æ —Å—Ç–∞—Ç—É—Å
                status = random.choices(statuses, weights=weights)[0]
                
                applications_data.append((
                    job_id,
                    user_id,
                    applied_at,
                    status
                ))
            
            # –ó–∞–ø–∏—Å—É—î–º–æ –ø–∞—á–∫—É –≤ –±–∞–∑—É
            insert_query = """
                INSERT INTO job_applications (job_id, user_id, applied_at, status) 
                VALUES %s
            """
            execute_values(write_cursor, insert_query, applications_data)
            
            # –§—ñ–∫—Å—É—î–º–æ –∑–º—ñ–Ω–∏
            conn.commit()
            
            inserted_total += len(applications_data)
            print(f"–ü—Ä–æ–≥—Ä–µ—Å: {inserted_total} —è–∫—ñ—Å–Ω–∏—Ö –∑–∞—è–≤–æ–∫ –¥–æ–¥–∞–Ω–æ...")
            
            # (–û–ø—Ü—ñ–æ–Ω–∞–ª—å–Ω–æ) –Ø–∫—â–æ –º–∏ –¥–æ—Å—è–≥–ª–∏ –º–µ—Ç–∏, –º–æ–∂–Ω–∞ –≤–∏–π—Ç–∏ —Ä–∞–Ω—ñ—à–µ
            if inserted_total >= target_count:
                print("–î–æ—Å—è–≥–Ω—É—Ç–æ —Ü—ñ–ª—å–æ–≤–æ—ó –∫—ñ–ª—å–∫–æ—Å—Ç—ñ –∑–∞–ø–∏—Å—ñ–≤.")
                break

        print(f"–£—Å–ø—ñ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ! –í—Å—å–æ–≥–æ –¥–æ–¥–∞–Ω–æ: {inserted_total}")

    except Exception as e:
        print(f"–ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞: {e}")
        if conn: 
            conn.rollback()
    finally:
        # –ó–∞–∫—Ä–∏–≤–∞—î–º–æ –≤—Å–µ –∫–æ—Ä–µ–∫—Ç–Ω–æ
        if read_cursor: 
            read_cursor.close()
        if write_cursor: 
            write_cursor.close()
        if conn: 
            conn.close()

# –ó–∞–ø–æ–≤–Ω–µ–Ω–Ω—è —Ç–∞–±–ª–∏—Ü—ñ Job_Status_History –∑ —Ç–æ—á–Ω–æ—é —ñ—Å—Ç–æ—Ä—ñ—î—é –∑–º—ñ–Ω
def populate_dense_history(db_config, batch_size=50000):
    try:
        conn = psycopg2.connect(**db_config)
        read_cursor = conn.cursor(name='jobs_reader_dense', withhold=True)
        write_cursor = conn.cursor()

        print("–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —â—ñ–ª—å–Ω–æ—ó —ñ—Å—Ç–æ—Ä—ñ—ó (Density Mode)...")
        read_cursor.execute("SELECT job_id, posted_at, last_updated, is_active FROM jobs")

        inserted_count = 0
        total_records = 0
        
        while True:
            rows = read_cursor.fetchmany(batch_size)
            if not rows:
                break
            
            history_entries = []
            
            for job_id, posted_at, last_updated, is_active in rows:
                # 1. –ü–æ—á–∞—Ç–æ–∫ –∑–∞–≤–∂–¥–∏ –æ–¥–Ω–∞–∫–æ–≤–∏–π
                history_entries.append((job_id, 'active', posted_at))
                
                lifespan = (last_updated - posted_at).total_seconds()
                
                # –Ø–∫—â–æ –≤–∞–∫–∞–Ω—Å—ñ—è –∂–∏–≤–µ –º–µ–Ω—à–µ 1 –¥–Ω—è, —ñ—Å—Ç–æ—Ä—ñ—é –Ω–µ —Ä–æ–∑–¥—É–≤–∞—î–º–æ
                if lifespan < 86400:
                    if not is_active:
                         history_entries.append((job_id, 'closed', last_updated))
                    continue

                # 2. –ì–ï–ù–ï–†–ê–¶–Ü–Ø –ü–†–û–ú–Ü–ñ–ù–ò–• –°–¢–ê–ù–Ü–í
                # –°–ø—Ä–æ–±—É—î–º–æ –≤—Å—Ç–∞–≤–∏—Ç–∏ 1 –∞–±–æ 2 —Ü–∏–∫–ª–∏ "–ø–∞—É–∑–∏" –≤—Å–µ—Ä–µ–¥–∏–Ω—É –ø–µ—Ä—ñ–æ–¥—É –∂–∏—Ç—Ç—è
                # –¢–æ–±—Ç–æ: Active -> [Paused -> Active] -> [Paused -> Active] -> ...
                
                num_pauses = random.choices([0, 1, 2], weights=[0.1, 0.6, 0.3])[0]
                
                current_time = posted_at
                step = lifespan / (num_pauses * 2 + 2) # –†–æ–∑–±–∏–≤–∞—î–º–æ —á–∞—Å –Ω–∞ —Ä—ñ–≤–Ω—ñ —à–º–∞—Ç–∫–∏
                
                for i in range(num_pauses):
                    # Paused
                    current_time += timedelta(seconds=step)
                    history_entries.append((job_id, 'paused', current_time))
                    
                    # Active (–≤—ñ–¥–Ω–æ–≤–ª–µ–Ω–Ω—è)
                    current_time += timedelta(seconds=step)
                    history_entries.append((job_id, 'active', current_time))

                # 3. –§–Ü–ù–ê–õ–¨–ù–ò–ô –°–¢–ê–ù
                if not is_active:
                    # –Ø–∫—â–æ –≤–∞–∫–∞–Ω—Å—ñ—è –∑–∞–∫—Ä–∏—Ç–∞, –æ—Å—Ç–∞–Ω–Ω—ñ–π –∑–∞–ø–∏—Å - closed
                    history_entries.append((job_id, 'closed', last_updated))
                else:
                    # –Ø–∫—â–æ –≤–∞–∫–∞–Ω—Å—ñ—è –¥–æ—Å—ñ –∞–∫—Ç–∏–≤–Ω–∞, –ø–µ—Ä–µ–∫–æ–Ω—É—î–º–æ—Å—è, —â–æ –æ—Å—Ç–∞–Ω–Ω—ñ–π –∑–∞–ø–∏—Å 'active'
                    # (–ú–∏ —Ü–µ –≤–∂–µ –∑—Ä–æ–±–∏–ª–∏ –≤ —Ü–∏–∫–ª—ñ, –∞–ª–µ —è–∫—â–æ —Ü–∏–∫–ª—ñ–≤ –±—É–ª–æ 0 - —Ç–æ –ø–µ—Ä—à–∏–π –∑–∞–ø–∏—Å —ñ —î –æ—Å—Ç–∞–Ω–Ω—ñ–º)
                    pass

            # –ó–∞–ø–∏—Å
            execute_values(write_cursor, """
                INSERT INTO job_status_history (job_id, status, changed_at) 
                VALUES %s
            """, history_entries)
            
            conn.commit()
            total_records += len(history_entries)
            inserted_count += len(rows)
            
            if inserted_count % 100000 == 0:
                print(f"–û–±—Ä–æ–±–ª–µ–Ω–æ {inserted_count} –≤–∞–∫–∞–Ω—Å—ñ–π. –ó–≥–µ–Ω–µ—Ä–æ–≤–∞–Ω–æ –∑–∞–ø–∏—Å—ñ–≤ —ñ—Å—Ç–æ—Ä—ñ—ó: {total_records}")

        print(f"–ì–æ—Ç–æ–≤–æ! –í—Å—å–æ–≥–æ –∑–∞–ø–∏—Å—ñ–≤ –≤ —ñ—Å—Ç–æ—Ä—ñ—ó: {total_records}")
        print(f"–°–µ—Ä–µ–¥–Ω—è –∫—ñ–ª—å–∫—ñ—Å—Ç—å –∑–∞–ø–∏—Å—ñ–≤ –Ω–∞ –≤–∞–∫–∞–Ω—Å—ñ—é: {total_records / inserted_count:.2f}")

    except Exception as e:
        print(f"–ü–æ–º–∏–ª–∫–∞: {e}")
        if conn: 
            conn.rollback()
    finally:
        if read_cursor: 
            read_cursor.close()
        if write_cursor: 
            write_cursor.close()
        if conn: 
            conn.close()

# –§—É–Ω–∫—Ü—ñ—è –¥–ª—è –≤–Ω–µ—Å–µ–Ω–Ω—è —Ö–∞–æ—Å—É –≤ –±–∞–∑—É –¥–∞–Ω–∏—Ö (Chaos Monkey)
def apply_chaos(db_config):
    try:
        conn = psycopg2.connect(**db_config)
        cursor = conn.cursor()
        print("–ó–∞–ø—É—Å–∫ Chaos Monkey... –ü—Å—É—î–º–æ –¥–∞–Ω—ñ –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è üêí")

        # 1. –°—Ç–≤–æ—Ä—é—î–º–æ –ø—ñ–∑–Ω—ñ –∞–ø–¥–µ–π—Ç–∏ (last_updated < posted_at)
        print("- –°—Ç–≤–æ—Ä—é—î–º–æ –ª–æ–≥—ñ—á–Ω—ñ –ø–æ–º–∏–ª–∫–∏ –≤ –¥–∞—Ç–∞—Ö –æ–Ω–æ–≤–ª–µ–Ω–Ω—è...")
        cursor.execute("""
            UPDATE jobs 
            SET last_updated = posted_at - interval '1 day' * (random() * 10 + 1)::int
            WHERE job_id IN (SELECT job_id FROM jobs TABLESAMPLE SYSTEM(1));
        """)

        # 2. –î–æ–¥–∞—î–º–æ NULL-–∏ –≤ –æ–±–æ–≤'—è–∑–∫–æ–≤—ñ –∑–∞ –ª–æ–≥—ñ–∫–æ—é, –∞–ª–µ –Ω–µ –∑–∞ —Å—Ö–µ–º–æ—é –ø–æ–ª—è
        print("- –í–∏–¥–∞–ª—è—î–º–æ –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó —Ç–∞ –ª–æ–∫–∞—Ü—ñ—ó (—Å—Ç–≤–æ—Ä—é—î–º–æ NULL)...")
        cursor.execute("""
            UPDATE jobs 
            SET category = NULL, location = NULL
            WHERE job_id IN (SELECT job_id FROM jobs TABLESAMPLE SYSTEM(0.5));
        """)

        # 3. –°—Ç–≤–æ—Ä—é—î–º–æ –¥—É–±–ª—ñ–∫–∞—Ç–∏ –≤ job_views
        print("- –ì–µ–Ω–µ—Ä—É—î–º–æ –¥—É–±–ª—ñ–∫–∞—Ç–∏ –≤ –ø–µ—Ä–µ–≥–ª—è–¥–∞—Ö (—Ü–µ –∑–∞–π–º–µ —Ç—Ä–æ—Ö–∏ —á–∞—Å—É)...")
        cursor.execute("""
            INSERT INTO job_views (job_id, user_id, viewed_at)
            SELECT job_id, user_id, viewed_at 
            FROM job_views 
            TABLESAMPLE SYSTEM(0.2); 
        """)

        # 4. –°—Ç–≤–æ—Ä—é—î–º–æ NULL-—Å—Ç–∞—Ç—É—Å–∏ –≤ –∑–∞—è–≤–∫–∞—Ö
        print("- –°—Ç–≤–æ—Ä—é—î–º–æ –ø–æ—Ä–æ–∂–Ω—ñ —Å—Ç–∞—Ç—É—Å–∏ –≤ –∑–∞—è–≤–∫–∞—Ö...")
        cursor.execute("""
            UPDATE job_applications 
            SET status = NULL
            WHERE application_id IN (SELECT application_id FROM job_applications TABLESAMPLE SYSTEM(1));
        """)

        conn.commit()
        print("–ì–æ—Ç–æ–≤–æ! –¢–µ–ø–µ—Ä —Ç–≤–æ—è –±–∞–∑–∞ –¥–∞–Ω–∏—Ö —Å–ø–æ–≤–Ω–µ–Ω–∞ —Å—é—Ä–ø—Ä–∏–∑—ñ–≤ –¥–ª—è –¥–µ–±–∞–≥—É. üî•")

    except Exception as e:
        print(f"–ü–æ–º–∏–ª–∫–∞ —Ö–∞–æ—Å—É: {e}")
        if conn: 
            conn.rollback()
    finally:
        if cursor: 
            cursor.close()
        if conn: 
            conn.close()

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è (–∑–∞–º—ñ–Ω–∏ –Ω–∞ —Å–≤–æ—ó –¥–∞–Ω—ñ)
config = {
    "dbname": config("DB_NAME", default="job_db"),
    "user": config("DB_USER", default="job_user"),
    "password": config("DB_NAME", default="job_password"),
    "host": config("DB_HOST", default="localhost"),
    "port": config("DB_PORT", default="5432"),
}

if __name__ == "__main__":
    # populate_companies(config)
    # populate_jobs(config)
    # populate_views(config)
    # populate_precise_applications(config)
    # populate_dense_history(config)
    apply_chaos(config)